<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>HTML Scraping &mdash; The Hitchhiker&#39;s Guide to Python</title>
    
    <link rel="stylesheet" href="../_static/flasky.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.0.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <link rel="top" title="The Hitchhiker&#39;s Guide to Python" href="../index.html" />
    <link rel="next" title="Command Line Applications" href="cli.html" />
    <link rel="prev" title="Web Applications" href="web.html" />
   
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9">

  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="cli.html" title="Command Line Applications"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="web.html" title="Web Applications"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">The Hitchhiker&#39;s Guide to Python</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="html-scraping">
<h1>HTML Scraping<a class="headerlink" href="#html-scraping" title="Permalink to this headline">¶</a></h1>
<div class="section" id="web-scraping">
<h2>Web Scraping<a class="headerlink" href="#web-scraping" title="Permalink to this headline">¶</a></h2>
<p>Web sites are written using HTML, which means that each web page is a
structured document. Sometimes it would be great to obtain some data from
them and preserve the structure while we&#8217;re at it. Web sites don&#8217;t always
provide their data in comfortable formats such as <tt class="docutils literal"><span class="pre">csv</span></tt> or <tt class="docutils literal"><span class="pre">json</span></tt>.</p>
<p>This is where web scraping comes in. Web scraping is the practice of using a
computer program to sift through a web page and gather the data that you need
in a format most useful to you while at the same time preserving the structure
of the data.</p>
</div>
<div class="section" id="lxml-and-requests">
<h2>lxml and Requests<a class="headerlink" href="#lxml-and-requests" title="Permalink to this headline">¶</a></h2>
<p><a class="reference external" href="http://lxml.de/">lxml</a> is a pretty extensive library written for parsing
XML and HTML documents really fast. It even handles messed up tags. We will
also be using the <a class="reference external" href="http://docs.python-requests.org/en/latest/">Requests</a>
module instead of the already built-in urlib2 due to improvements in speed and
readability. You can easily install both using <tt class="docutils literal"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">lxml</span></tt> and
<tt class="docutils literal"><span class="pre">pip</span> <span class="pre">install</span> <span class="pre">requests</span></tt>.</p>
<p>Lets start with the imports:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">lxml</span> <span class="kn">import</span> <span class="n">html</span>
<span class="kn">import</span> <span class="nn">requests</span>
</pre></div>
</div>
<p>Next we will use <tt class="docutils literal"><span class="pre">requests.get</span></tt> to retrieve the web page with our data
and parse it using the <tt class="docutils literal"><span class="pre">html</span></tt> module and save the results in <tt class="docutils literal"><span class="pre">tree</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">page</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s">&#39;http://econpy.pythonanywhere.com/ex/001.html&#39;</span><span class="p">)</span>
<span class="n">tree</span> <span class="o">=</span> <span class="n">html</span><span class="o">.</span><span class="n">fromstring</span><span class="p">(</span><span class="n">page</span><span class="o">.</span><span class="n">text</span><span class="p">)</span>
</pre></div>
</div>
<p><tt class="docutils literal"><span class="pre">tree</span></tt> now contains the whole HTML file in a nice tree structure which
we can go over two different ways: XPath and CSSSelect. In this example, I
will focus on the former.</p>
<p>XPath is a way of locating information in structured documents such as
HTML or XML documents. A good introduction to XPath is on
<a class="reference external" href="http://www.w3schools.com/xpath/default.asp">W3Schools</a> .</p>
<p>There are also various tools for obtaining the XPath of elements such as
FireBug for Firefox or the Chrome Inspector. If you&#8217;re using Chrome, you
can right click an element, choose &#8216;Inspect element&#8217;, highlight the code,
right click again and choose &#8216;Copy XPath&#8217;.</p>
<p>After a quick analysis, we see that in our page the data is contained in
two elements - one is a div with title &#8216;buyer-name&#8217; and the other is a
span with class &#8216;item-price&#8217;:</p>
<div class="highlight-python"><pre>&lt;div title="buyer-name"&gt;Carson Busses&lt;/div&gt;
&lt;span class="item-price"&gt;$29.95&lt;/span&gt;</pre>
</div>
<p>Knowing this we can create the correct XPath query and use the lxml
<tt class="docutils literal"><span class="pre">xpath</span></tt> function like this:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="c">#This will create a list of buyers:</span>
<span class="n">buyers</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//div[@title=&quot;buyer-name&quot;]/text()&#39;</span><span class="p">)</span>
<span class="c">#This will create a list of prices</span>
<span class="n">prices</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">xpath</span><span class="p">(</span><span class="s">&#39;//span[@class=&quot;item-price&quot;]/text()&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>Lets see what we got exactly:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">print</span> <span class="s">&#39;Buyers: &#39;</span><span class="p">,</span> <span class="n">buyers</span>
<span class="k">print</span> <span class="s">&#39;Prices: &#39;</span><span class="p">,</span> <span class="n">prices</span>
</pre></div>
</div>
<div class="highlight-python"><pre>Buyers:  ['Carson Busses', 'Earl E. Byrd', 'Patty Cakes',
'Derri Anne Connecticut', 'Moe Dess', 'Leda Doggslife', 'Dan Druff',
'Al Fresco', 'Ido Hoe', 'Howie Kisses', 'Len Lease', 'Phil Meup',
'Ira Pent', 'Ben D. Rules', 'Ave Sectomy', 'Gary Shattire',
'Bobbi Soks', 'Sheila Takya', 'Rose Tattoo', 'Moe Tell']

Prices:  ['$29.95', '$8.37', '$15.26', '$19.25', '$19.25',
'$13.99', '$31.57', '$8.49', '$14.47', '$15.86', '$11.11',
'$15.98', '$16.27', '$7.50', '$50.85', '$14.26', '$5.68',
'$15.00', '$114.07', '$10.09']</pre>
</div>
<p>Congratulations! We have successfully scraped all the data we wanted from
a web page using lxml and Requests. We have it stored in memory as two
lists. Now we can do all sorts of cool stuff with it: we can analyze it
using Python or we can save it to a file and share it with the world.</p>
<p>A cool idea to think about is modifying this script to iterate through
the rest of the pages of this example dataset or rewriting this
application to use threads for improved speed.</p>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper"><h1><a href="http://python-guide.org">Python指南.</a></h1>
<p>
  这份“傻逼”的指南旨在给Python的新老手们提供一个不错的参考书来安装、配置和使用Python
</p>

<h3>获取更新</h3>
<p>收取更新消息</p>

<p><a href="http://tinyletter.com/kennethreitz">订阅新闻邮件</a></p>

<h3>捐助</h3>
<p>
    如果你喜欢这个指南，给作者捐点Money吧<a href="https://www.gittip.com/kennethreitz/">on Gittip</a>:
</p>
<p>
  <iframe style="border: 0; margin: 0; padding: 0;"
      src="https://www.gittip.com/kennethreitz/widget.html"
      width="48pt" height="20pt"></iframe>
</p>
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">HTML Scraping</a><ul>
<li><a class="reference internal" href="#web-scraping">Web Scraping</a></li>
<li><a class="reference internal" href="#lxml-and-requests">lxml and Requests</a></li>
</ul>
</li>
</ul>
<h3>Related Topics</h3>
<ul>
  <li><a href="../index.html">Documentation overview</a><ul>
      <li>Previous: <a href="web.html" title="previous chapter">Web Applications</a></li>
      <li>Next: <a href="cli.html" title="next chapter">Command Line Applications</a></li>
  </ul></li>
</ul>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/scenarios/scrape.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy; Copyright 2013. A <a href="http://kennethreitz.com/pages/open-projects.html">Kenneth Reitz</a> Project. <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/"> Creative Commons Share-Alike 3.0</a>.
    </div>
    <a href="https://github.com/kennethreitz/python-guide" class="github">
        <img style="position: absolute; top: 0; right: 0; border: 0;" src="http://s3.amazonaws.com/github/ribbons/forkme_right_darkblue_121621.png" alt="Fork me on GitHub" />
    </a>

    <script type="text/javascript">

      var _gaq2 = _gaq2 || [];
      _gaq2.push(['_setAccount', 'UA-8742933-10']);
      _gaq2.push(['_setDomainName', 'none']);
      _gaq2.push(['_setAllowLinker', true]);
      _gaq2.push(['_trackPageview']);

      (function() {
        var ga2 = document.createElement('script'); ga2.type = 'text/javascript'; ga2.async = true;
        ga2.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
        var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga2, s);
      })();

    </script>

    <script type="text/javascript">
      (function() {
        var t   = document.createElement('script');
        t.type  = 'text/javascript';
        t.async = true;
        t.id    = 'gauges-tracker';
        t.setAttribute('data-site-id',
                       '4ddc1cfaf5a1f50fcc000001');
        t.src = '//secure.gaug.es/track.js';
        var s = document.getElementsByTagName('script')[0];
        s.parentNode.insertBefore(t, s);
      })();
    </script>
  </body>
</html>